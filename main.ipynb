{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/nanosemantics/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nanosemantics/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/nanosemantics/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/nanosemantics/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import docx\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import deeppavlov\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ftfy import fix_text\n",
    "from glob import glob\n",
    "from pymystem3 import Mystem\n",
    "from openpyxl import load_workbook\n",
    "from transformers import BertTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "from tika import parser\n",
    "from string import punctuation\n",
    "\n",
    "from deeppavlov.models.tokenizers.ru_sent_tokenizer import RuSentTokenizer as SentTokenizer\n",
    "from deeppavlov.models.tokenizers.ru_tokenizer import RussianTokenizer as Tokenizer\n",
    "\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#import win32com.client as win32\n",
    "#from win32com.client import constants\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка файла ППР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/1000-11-ППР-УПНГ.docx']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = glob(r'./data/*ППР*.docx', recursive=True)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(path):\n",
    "    doc_texts = []\n",
    "    doc = docx.Document(path)\n",
    "    text = '\\n'.join([doc.paragraphs[i].text for i in range(len(doc.paragraphs))])\n",
    "    splt_texs = [re.sub(r'\\s+', ' ', sentence) for sentence in text.split('\\n') if sentence and sentence != ' ']\n",
    "    doc_texts.extend(splt_texs)\n",
    "    return doc_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "class Stemmer(object):\n",
    "    def __init__(self):\n",
    "        self.mystem = Mystem()\n",
    "        \n",
    "    #Preprocess function\n",
    "    def preprocess_text(self, text):\n",
    "        norm_tokens = self.mystem.lemmatize(text)\n",
    "        norm_tokens = [token.strip('\\n') for token in norm_tokens if token not in russian_stopwords and token != \" \" and token.strip() not in punc]\n",
    "        text = \" \".join(norm_tokens)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ppr = read_docx(paths[0])\n",
    "df = pd.DataFrame(doc_ppr, columns=['sent'])\n",
    "df['len'] = df['sent'].apply(lambda x: len(x))\n",
    "\n",
    "drop_ind = df[(df['sent'].apply(lambda x: '1000/' in x) & df['len'].apply(lambda x: x <= 20)) | df['len'].apply(lambda x: x < 17)].index\n",
    "df.drop(drop_ind, axis=0, inplace=True)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "punc = punctuation\n",
    "punc += '«»―'\n",
    "\n",
    "stemmer = Stemmer()\n",
    "df['lemmatize_sent'] = df['sent'].apply(lambda text: stemmer.preprocess_text(text))\n",
    "\n",
    "doc_ppr_raw = df['sent'].values\n",
    "doc_ppr = df['lemmatize_sent'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['проект производство работа',\n",
       "       'обустройство тазовский месторождение',\n",
       "       'установка подготовка нефть газ',\n",
       "       'разрабатывать инженер отдел идипс ао премьерстрой глебов д',\n",
       "       'г тюмень 2019г', 'l общий положение',\n",
       "       'настоящий проект производство работа распространяться организация безопасный производство контроль приемка основной работа строительство объект : « обустройство тазовский месторождение установка подготовка нефть газ',\n",
       "       'административный отношение объект строительство : « обустройство тазовский месторождение установка подготовка нефть газ располагать территория тазовский район ямало-ненецкий автономный округ тюменский область 8 км юго-восток поселок газ сало',\n",
       "       'близкий населенный пункт район строительство являться поселок газ сало также поселок тазовский',\n",
       "       'настоящий ППР разрабатывать ао премьерстрой основание договор № ГНР 19 11023 00070 р 15 выполнение строительно-монтажный работа'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ppr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer = SentTokenizer()\n",
    "tokenizer = Tokenizer(stopwords=stopwords.words('russian'), alphas_only=False)\n",
    "#bert_tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-sentence', do_lower_case=True, do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка файла ПОС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(path):\n",
    "    data = parser.from_file(path)\n",
    "    data = ' '.join(re.sub(r'\\n+', '\\n', data['content']).split('\\n'))\n",
    "    return re.sub('\\s+', ' ', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/Раздел ПД N6 ПОС-1 (1000-11-П-ПОС, 2020).pdf',\n",
       " './data/Раздел ПД N6 ПОС УПНГ (1000-11-П-ПОС, 2019).pdf']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_paths = glob(r'./data/*Раздел*.pdf', recursive=True)\n",
    "pdf_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_pos = sent_tokenizer([read_pdf(pdf_paths[1])])[0]\n",
    "#doc_pos_2 = sent_tokenizer([read_pdf(pdf_paths[1])])\n",
    "\n",
    "df = pd.DataFrame(doc_pos, columns=['sent'])\n",
    "df = df[~df['sent'].apply(lambda x: 'Text' in x or 'AutoCad' in x or 'normacs' in x or 'гипровостокнефть' in x.lower())]\n",
    "df['len'] = df['sent'].apply(lambda x: len(x))\n",
    "\n",
    "map_ = {ord('\\uf0b4'): '',\n",
    "        ord('\\uf02b'): '',\n",
    "        ord('\\uf03d'): '',\n",
    "        ord('\\uf0d7'): '',\n",
    "        ord('\\uf02d'): '',\n",
    "        ord('\\uf0bb'): ''}\n",
    "\n",
    "df = df[~df['sent'].apply(lambda x: 'Т е к с т о в а я' in x or 'Р а з д е л' in x or 'Ф а й л' in x or 'П о д п и с ь' in x or '1000/11-П-ПОС-ПрилБ_4 1000/11-П-ПОС-ПрилВ_4' in x)]\n",
    "df['sent'] = df['sent'].apply(lambda x: x.translate(map_))\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[df['len']> 17]\n",
    "df['lemmatize_sent'] = df['sent'].apply(lambda text: stemmer.preprocess_text(text))\n",
    "\n",
    "doc_pos_raw = df['sent'].values\n",
    "doc_pos = df['lemmatize_sent'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019 свидетельство № 0002 2012 6315200011 07 7 декабрь 2012 г заказчик  –  ооо газпромнефть ямал обустройство тазовский месторождение',\n",
       "       'установка подготовка нефть газ проектный документация раздел 6',\n",
       "       'проект организация строительство 1000 11 п пос 6 изм',\n",
       "       'дата 4 1788 19 27.03 19 з м',\n",
       "       'проект организация строительство 1000 11 п пос 6 главный инженер н п попов главный инженер проект н володин з м',\n",
       "       'кол уч лист № док', 'подпись дата н',\n",
       "       '4 зам .)  1000 11 п сп состав проектный документация 1000 11 п пос раздел 6',\n",
       "       'проект организация строительство', 'текстовой часть изм'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_pos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительный препроцессинг документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_pos = [re.sub(r'[\\)\\(»«:.,/;•]{1}', '', sent) for sent in doc_pos]\n",
    "doc_ppr = [re.sub(r'[\\)\\(»«:.,/;•]{1}', '', sent).strip() for sent in doc_ppr]\n",
    "\n",
    "doc_pos = [re.sub(r'[_—–]{1}', ' ', sent) for sent in doc_pos]\n",
    "doc_ppr = [re.sub(r'[_—–]{1}', ' ', sent).strip() for sent in doc_ppr]\n",
    "\n",
    "doc_pos = [re.sub(r'\\s+', ' ', sent) for sent in doc_pos]\n",
    "doc_ppr = [re.sub(r'\\s+', ' ', sent) for sent in doc_ppr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(doc_pos) == len(doc_pos_raw)) & (len(doc_ppr) == len(doc_ppr_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ppr = list(doc_ppr)\n",
    "doc_pos = list(doc_pos)\n",
    "\n",
    "#tokenized_ppr = [[token.lower() for token in bert_tokenizer.tokenize(sentence)] for sentence in doc_ppr]\n",
    "#tokenized_pos = [[token.lower() for token in bert_tokenizer.tokenize(sentence)] for sentence in doc_pos]\n",
    "\n",
    "tokenized_ppr = tokenizer(doc_ppr)\n",
    "tokenized_pos = tokenizer(doc_pos)\n",
    "\n",
    "train_tokenized_sents = tokenized_ppr + tokenized_pos\n",
    "train_sents = doc_ppr + doc_pos\n",
    "train_sents_raw = list(doc_ppr_raw) + list(doc_pos_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ppr' for _ in range(len(list(doc_ppr_raw)))] + ['pos' for _ in range(len(list(doc_pos_raw)))]\n",
    "\n",
    "train_sents_raw_df = pd.DataFrame(train_sents_raw, columns=['sent'])\n",
    "train_sents_raw_df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['проект', 'производство', 'работа'],\n",
       " ['обустройство', 'тазовский', 'месторождение'],\n",
       " ['установка', 'подготовка', 'нефть', 'газ'],\n",
       " ['разрабатывать',\n",
       "  'инженер',\n",
       "  'отдел',\n",
       "  'идипс',\n",
       "  'ао',\n",
       "  'премьерстрой',\n",
       "  'глебов',\n",
       "  'д'],\n",
       " ['г', 'тюмень', '2019г'],\n",
       " ['l', 'общий', 'положение'],\n",
       " ['настоящий',\n",
       "  'проект',\n",
       "  'производство',\n",
       "  'работа',\n",
       "  'распространяться',\n",
       "  'организация',\n",
       "  'безопасный',\n",
       "  'производство',\n",
       "  'контроль',\n",
       "  'приемка',\n",
       "  'основной',\n",
       "  'работа',\n",
       "  'строительство',\n",
       "  'объект',\n",
       "  'обустройство',\n",
       "  'тазовский',\n",
       "  'месторождение',\n",
       "  'установка',\n",
       "  'подготовка',\n",
       "  'нефть',\n",
       "  'газ'],\n",
       " ['административный',\n",
       "  'отношение',\n",
       "  'объект',\n",
       "  'строительство',\n",
       "  'обустройство',\n",
       "  'тазовский',\n",
       "  'месторождение',\n",
       "  'установка',\n",
       "  'подготовка',\n",
       "  'нефть',\n",
       "  'газ',\n",
       "  'располагать',\n",
       "  'территория',\n",
       "  'тазовский',\n",
       "  'район',\n",
       "  'ямало-ненецкий',\n",
       "  'автономный',\n",
       "  'округ',\n",
       "  'тюменский',\n",
       "  'область',\n",
       "  '8',\n",
       "  'км',\n",
       "  'юго-восток',\n",
       "  'поселок',\n",
       "  'газ',\n",
       "  'сало'],\n",
       " ['близкий',\n",
       "  'населенный',\n",
       "  'пункт',\n",
       "  'район',\n",
       "  'строительство',\n",
       "  'являться',\n",
       "  'поселок',\n",
       "  'газ',\n",
       "  'сало',\n",
       "  'также',\n",
       "  'поселок',\n",
       "  'тазовский'],\n",
       " ['настоящий',\n",
       "  'ппр',\n",
       "  'разрабатывать',\n",
       "  'ао',\n",
       "  'премьерстрой',\n",
       "  'основание',\n",
       "  'договор',\n",
       "  '№',\n",
       "  'гнр',\n",
       "  '19',\n",
       "  '11023',\n",
       "  '00070',\n",
       "  'р',\n",
       "  '15',\n",
       "  'выполнение',\n",
       "  'строительно-монтажный',\n",
       "  'работа']]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized_sents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение векторизатора Word2Vec для получения векторных представлений слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SIZE = 200\n",
    "\n",
    "model = Word2Vec(sentences=train_tokenized_sents, vector_size=VECTOR_SIZE, workers=10, alpha=0.025, epochs=10, min_count=2, max_vocab_size=100000)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на слова, которые лежат близко в пространстве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('прокладываться', 0.9974771738052368),\n",
       " ('электрообогрев', 0.9960862994194031),\n",
       " ('порожний', 0.9948625564575195),\n",
       " ('опора', 0.9946585297584534),\n",
       " ('штуцер', 0.9946041107177734),\n",
       " ('пролагать', 0.994421660900116),\n",
       " ('факел', 0.9942864775657654),\n",
       " ('химический', 0.9941856861114502),\n",
       " ('верхний', 0.9941197037696838),\n",
       " ('наполнительный', 0.9940759539604187)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('электрический')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('работник', 0.9664180874824524),\n",
       " ('нетрезвый', 0.956488311290741),\n",
       " ('время', 0.9547008275985718),\n",
       " ('обеденный', 0.9535852670669556),\n",
       " ('проходить', 0.9472776651382446),\n",
       " ('нахождение', 0.9458402395248413),\n",
       " ('зимний', 0.9435594081878662),\n",
       " ('иметь', 0.9431988000869751),\n",
       " ('инструктаж', 0.9416723847389221),\n",
       " ('обратно', 0.939297616481781)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('рабочий')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаем document frequency для использования вместе с term frequency при расчете векторов предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_idf = {}\n",
    "\n",
    "for sent in train_tokenized_sents:\n",
    "    for token in set(sent):\n",
    "        if token in token_idf:\n",
    "            token_idf[token] += 1\n",
    "        else:\n",
    "            token_idf[token] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаем векторные представления предложений, как среднее всех векторов слов умноженных на Tf * Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nanosemantics/sasha/num_seq2seq/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  del sys.path[0]\n",
      "/home/nanosemantics/sasha/num_seq2seq/lib/python3.6/site-packages/numpy/core/_methods.py:151: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2783\n"
     ]
    }
   ],
   "source": [
    "sentence_vectors = np.empty((len(train_tokenized_sents), VECTOR_SIZE))\n",
    "a, n = 0, 0\n",
    "\n",
    "for i, tokenized_sent in enumerate(train_tokenized_sents):\n",
    "    sentence_vector = np.empty((len(tokenized_sent), VECTOR_SIZE))\n",
    "    \n",
    "    for j, token in enumerate(tokenized_sent):\n",
    "        try:\n",
    "            a += 1\n",
    "            token_vector = model.wv[token.lower()]\n",
    "            tf =  tokenized_sent.count(token) / len(tokenized_sent)\n",
    "            df = token_idf[token]\n",
    "            tfidf = tf / np.log(df)\n",
    "            sentence_vector[j] = token_vector * tfidf\n",
    "        except:\n",
    "            n += 1\n",
    "            #sentence_vector[j] = sentence_vector.mean(axis=0)\n",
    "            pass\n",
    "    pooled_sentence_vector = sentence_vector.mean(axis=0)\n",
    "    sentence_vectors[i] = pooled_sentence_vector \n",
    "    \n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82910\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_tokenized_sents) == sentence_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ищем наиболее похожие предложения из документа ПОС на предложения документа ППР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_sent(input_sentence, voc_vectors):\n",
    "    tokenized_sentence = tokenizer([input_sentence])[0]\n",
    "    #tokenized_sentence = bert_tokenizer.tokenize(input_sentence)\n",
    "    NUM_TOKENS = len(tokenized_sentence)\n",
    "    #print(NUM_TOKENS)\n",
    "    input_vector = np.empty((NUM_TOKENS, VECTOR_SIZE))\n",
    "    n = 0\n",
    "    for i, token in enumerate(tokenized_sentence):\n",
    "        try:\n",
    "            token_vector = model.wv[token]\n",
    "            #print(token)\n",
    "            tf =  tokenized_sentence.count(token) / len(tokenized_sentence)\n",
    "            df = token_idf[token]\n",
    "            \n",
    "            tfidf = tf / np.log(df)\n",
    "            input_vector[i] = token_vector * tfidf\n",
    "        except:\n",
    "            pass\n",
    "            n += 1\n",
    "            #input_vector[i] = input_vector.mean(axis=0)\n",
    "        \n",
    "    #print('% null tokens: ', n / NUM_TOKENS)\n",
    "    input_vector = input_vector.mean(axis=0)\n",
    "    distances = {}\n",
    "    \n",
    "    for i, voc_vector in enumerate(voc_vectors):\n",
    "        dist = spatial.distance.cosine(input_vector, voc_vector)\n",
    "        #print(dist)\n",
    "        distances[i] = dist\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/nanosemantics/sasha/num_seq2seq/lib/python3.6/site-packages/scipy/spatial/distance.py:719: RuntimeWarning: overflow encountered in square\n",
      "  vv = np.average(np.square(v), weights=w)\n",
      "317it [01:47,  3.44it/s]/home/nanosemantics/sasha/num_seq2seq/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nanosemantics/sasha/num_seq2seq/lib/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "2026it [10:58,  3.51it/s]/home/nanosemantics/sasha/num_seq2seq/lib/python3.6/site-packages/scipy/spatial/distance.py:718: RuntimeWarning: overflow encountered in square\n",
      "  uu = np.average(np.square(u), weights=w)\n",
      "/home/nanosemantics/sasha/num_seq2seq/lib/python3.6/site-packages/scipy/spatial/distance.py:717: RuntimeWarning: overflow encountered in multiply\n",
      "  uv = np.average(u * v, weights=w)\n",
      "2873it [15:30,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "similar_sents_to_pos = {}\n",
    "\n",
    "for i, pos_sent in tqdm(enumerate(doc_pos)):\n",
    "    distances = most_similar_sent(pos_sent, sentence_vectors)\n",
    "\n",
    "    for ind, dist in sorted(distances.items(), key=lambda x: x[1], reverse=False)[:10]:\n",
    "        if train_sents_raw_df.iloc[ind, 1] == 'ppr':\n",
    "            multi_ind = str(i) + '_' + str(ind)\n",
    "            similar_sents_to_pos[multi_ind] = {\n",
    "                'pos_sent': doc_pos_raw[i], \n",
    "                'distance': dist, \n",
    "                'find_text': train_sents_raw_df.iloc[ind, 0], \n",
    "                'label': train_sents_raw_df.iloc[ind, 1]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получаем таблицу с данными следующего формата:\n",
    "\n",
    "pos_sent - предложение из документа ПОС</br>\n",
    "distance - косинусное расстояние между объектами (чем меньше, тем более предложения похожи друг на друга)</br>\n",
    "find_text - сопоставленное предложение из документа ППР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sents = pd.DataFrame.from_dict(similar_sents_to_pos, orient='index', columns=['pos_sent', 'distance', 'find_text'])\n",
    "sim_sents.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sents = sim_sents.sort_values(by=['pos_sent', 'distance']).drop_duplicates(['pos_sent']).sort_values(by='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>distance</th>\n",
       "      <th>find_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1151_681</th>\n",
       "      <td>Непосредственно перед выполнением разбивочных ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Непосредственно перед выполнением разбивочных ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809_1046</th>\n",
       "      <td>При прокладке каждая кабельная линия маркирует...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>При прокладке каждая кабельная линия маркирует...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806_1044</th>\n",
       "      <td>Работы по установке опорных конструкций для мо...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Работы по установке опорных конструкций для мо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396_853</th>\n",
       "      <td>При монтаже конструкций должно осуществляться ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>При монтаже конструкций должно осуществляться ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394_851</th>\n",
       "      <td>Для перевозки конструкций используется автотра...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Для перевозки конструкций используется автотра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671_136</th>\n",
       "      <td>Текстовая часть Опорожнение резервуара.</td>\n",
       "      <td>0.137068</td>\n",
       "      <td>6.1. Площадка слива;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740_1</th>\n",
       "      <td>Текстовая часть сверху с заделкой ее в верхней...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>«Обустройство Тазовского месторождения.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739_1</th>\n",
       "      <td>Текстовая часть 26.</td>\n",
       "      <td>0.143364</td>\n",
       "      <td>«Обустройство Тазовского месторождения.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>Текстовая часть Изм.</td>\n",
       "      <td>0.144354</td>\n",
       "      <td>«Обустройство Тазовского месторождения.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466_1</th>\n",
       "      <td>Текстовая часть трубопровода.</td>\n",
       "      <td>0.196456</td>\n",
       "      <td>«Обустройство Тазовского месторождения.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2799 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    pos_sent  distance  \\\n",
       "1151_681   Непосредственно перед выполнением разбивочных ...  0.000000   \n",
       "1809_1046  При прокладке каждая кабельная линия маркирует...  0.000000   \n",
       "1806_1044  Работы по установке опорных конструкций для мо...  0.000000   \n",
       "1396_853   При монтаже конструкций должно осуществляться ...  0.000000   \n",
       "1394_851   Для перевозки конструкций используется автотра...  0.000000   \n",
       "...                                                      ...       ...   \n",
       "1671_136             Текстовая часть Опорожнение резервуара.  0.137068   \n",
       "1740_1     Текстовая часть сверху с заделкой ее в верхней...  0.142056   \n",
       "2739_1                                   Текстовая часть 26.  0.143364   \n",
       "9_1                                     Текстовая часть Изм.  0.144354   \n",
       "1466_1                         Текстовая часть трубопровода.  0.196456   \n",
       "\n",
       "                                                   find_text  \n",
       "1151_681   Непосредственно перед выполнением разбивочных ...  \n",
       "1809_1046  При прокладке каждая кабельная линия маркирует...  \n",
       "1806_1044  Работы по установке опорных конструкций для мо...  \n",
       "1396_853   При монтаже конструкций должно осуществляться ...  \n",
       "1394_851   Для перевозки конструкций используется автотра...  \n",
       "...                                                      ...  \n",
       "1671_136                                6.1. Площадка слива;  \n",
       "1740_1               «Обустройство Тазовского месторождения.  \n",
       "2739_1               «Обустройство Тазовского месторождения.  \n",
       "9_1                  «Обустройство Тазовского месторождения.  \n",
       "1466_1               «Обустройство Тазовского месторождения.  \n",
       "\n",
       "[2799 rows x 3 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_sents.to_excel('sim_sents_3.xlsx', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>distance</th>\n",
       "      <th>find_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242_2</th>\n",
       "      <td>Установка подготовки нефти и газа».</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>Установка подготовки нефти и газа.»</td>\n",
       "      <td>ppr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540_290</th>\n",
       "      <td>Блок электродегидраторов (ЭГ-1-1...3).</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>- Блок электродегидраторов (ЭГ-1-1...3);</td>\n",
       "      <td>ppr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545_291</th>\n",
       "      <td>Блок дренажных емкостей (ДЕ-2-1,2).</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>- Блок дренажных емкостей (ДЕ-2-1,2);</td>\n",
       "      <td>ppr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551_293</th>\n",
       "      <td>Блок факельного сепаратора Сф-1.</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>- Блок факельного сепаратора Сф-1;</td>\n",
       "      <td>ppr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729_245</th>\n",
       "      <td>Растительность по трассе – кустарнички, тундро...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>Растительность по трассе – кустарнички, тундро...</td>\n",
       "      <td>ppr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542_312</th>\n",
       "      <td>Оппозитно расположены два опциональных модуля ...</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>- Азотно-воздушная станция с ресиверами (Рв-2-...</td>\n",
       "      <td>ppr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_sent  distance  \\\n",
       "242_2                   Установка подготовки нефти и газа».   0.00000   \n",
       "540_290              Блок электродегидраторов (ЭГ-1-1...3).   0.00000   \n",
       "545_291                 Блок дренажных емкостей (ДЕ-2-1,2).   0.00000   \n",
       "551_293                    Блок факельного сепаратора Сф-1.   0.00000   \n",
       "1729_245  Растительность по трассе – кустарнички, тундро...   0.00000   \n",
       "542_312   Оппозитно расположены два опциональных модуля ...   0.00007   \n",
       "\n",
       "                                                  find_text label  \n",
       "242_2                   Установка подготовки нефти и газа.»   ppr  \n",
       "540_290            - Блок электродегидраторов (ЭГ-1-1...3);   ppr  \n",
       "545_291               - Блок дренажных емкостей (ДЕ-2-1,2);   ppr  \n",
       "551_293                  - Блок факельного сепаратора Сф-1;   ppr  \n",
       "1729_245  Растительность по трассе – кустарнички, тундро...   ppr  \n",
       "542_312   - Азотно-воздушная станция с ресиверами (Рв-2-...   ppr  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_sents.sort_values(by='distance').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nanosemantics/sasha/num_seq2seq/lib/python3.6/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='distance', ylabel='Density'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(sim_sents['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7782.000000\n",
       "mean        0.000076\n",
       "std         0.000016\n",
       "min         0.000000\n",
       "25%         0.000065\n",
       "50%         0.000078\n",
       "75%         0.000089\n",
       "max         0.000100\n",
       "Name: distance, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_sents['distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Программа комплексной наладки узлов предусматривает на первой стадии раздельную работу специалистов различных профессий для первоначальной наладки отдельных видов оборудования с целью обеспечения надежности установки в проектном объеме, а затем - комплексную работу узловых бригад, создаваемых на этапе приемки, под техническим руководством бригадиров.',\n",
       "        4.152538522583793e-05,\n",
       "        'Поставка блоков с предприятий-изготовителей, сборочно-комплектовочных предприятий и баз к месту их установки, должна производиться в строгой технологической последовательности возведения объектов, предусмотренных графиком производства работ.',\n",
       "        'ppr'],\n",
       "       ['Программа комплексной наладки узлов предусматривает на первой стадии раздельную работу специалистов различных профессий для первоначальной наладки отдельных видов оборудования с целью обеспечения надежности установки в проектном объеме, а затем - комплексную работу узловых бригад, создаваемых на этапе приемки, под техническим руководством бригадиров.',\n",
       "        4.500993148925936e-05,\n",
       "        'На основании актов и осмотра комиссия определяет качество работ, готовность к сдаче в эксплуатацию и выдает письменное разрешение на ее включение. Подача напряжения производится эксплуатационным персоналом после письменного уведомления генерального подрядчика о том, что все работники с линии сняты и предупреждены о предстоящем включении. При бесперебойной нормальной работе в течение суток после включения приемочная комиссия оформляет акт передачи ее в эксплуатации.',\n",
       "        'ppr'],\n",
       "       ['Программа комплексной наладки узлов предусматривает на первой стадии раздельную работу специалистов различных профессий для первоначальной наладки отдельных видов оборудования с целью обеспечения надежности установки в проектном объеме, а затем - комплексную работу узловых бригад, создаваемых на этапе приемки, под техническим руководством бригадиров.',\n",
       "        4.5692115393070054e-05,\n",
       "        'Часто контрольные измерения необходимы для принятия проектных решений, например, когда необходимо выдать техническое решение на конкретный узел или заказать конструкции на заводе по определенным размерам. Ошибка в геодезических измерениях может вылиться в большие финансовые потери.',\n",
       "        'ppr'],\n",
       "       ['Программа комплексной наладки узлов предусматривает на первой стадии раздельную работу специалистов различных профессий для первоначальной наладки отдельных видов оборудования с целью обеспечения надежности установки в проектном объеме, а затем - комплексную работу узловых бригад, создаваемых на этапе приемки, под техническим руководством бригадиров.',\n",
       "        4.990409207972224e-05,\n",
       "        ' г) дать указание ответственному исполнителю работ по подготовке и приведению в исправность указанных в наряде-допуске инструментов, материалов, средств защиты, знаков, ограждений;',\n",
       "        'ppr'],\n",
       "       ['Освещение рабочих мест производится при помощи переносных прожекторных мачт.',\n",
       "        4.0225462393794764e-05,\n",
       "        'Площадка вокруг работающей буровой установки, радиус которой на 5м превышает длину стрелы, является опасной зоной, которая должна быть ограждена (сигнальной лентой, барьерами, либо каркасным ограждением) и установлены предупреждающие знаки. В периметре данной зоны могут находится только члены бригады.',\n",
       "        'ppr']], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_sents[sim_sents.distance < 0.00005].tail(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-47615df6954b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mind_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2240\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_inp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[\\)\\(»«:.,/;•]{1}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8459f685a439>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Preprocess function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnorm_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mnorm_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnorm_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrussian_stopwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sasha/num_seq2seq/lib/python3.6/site-packages/pymystem3/mystem.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mneed_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sasha/num_seq2seq/lib/python3.6/site-packages/pymystem3/mystem.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_analyze_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sasha/num_seq2seq/lib/python3.6/site-packages/pymystem3/mystem.py\u001b[0m in \u001b[0;36m_analyze_impl\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_mystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_procin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_procin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_NL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_procin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"при производстве сварочных работ в условиях отрицательных температурах\n",
    "окружающего воздуха необходим подогрев кромок на 100 - 150 °С. Сварочные работы в\n",
    "зимний период выполняются с устройством укрытий (типа палатки), защищающих сварщика\n",
    "и место проведения работ от атмосферных осадков и ветра\"\"\"\n",
    "\n",
    "ind_inp = 2240\n",
    "input_text = doc_pos[ind_inp]\n",
    "input_text = stemmer.preprocess_text(input_text)\n",
    "\n",
    "input_text = re.sub(r'[\\)\\(»«:.,/;•]{1}', '', input_text)\n",
    "input_text = re.sub(r'[-_—]{1}', ' ', input_text)\n",
    "input_text = re.sub(r'\\s+', ' ', input_text)\n",
    "input_text\n",
    "\n",
    "distances = most_similar_sent(input_text, sentence_vectors)\n",
    "print()\n",
    "#print('Input_text:', doc_pos_raw[ind_inp])\n",
    "print('Input_text:', input_text)\n",
    "print()\n",
    "\n",
    "for ind, dist in sorted(distances.items(), key=lambda x: x[1], reverse=False)[:10]:\n",
    "    if train_sents_raw_df.iloc[ind, 1] == 'ppr' and dist < 1e-4:\n",
    "        print('Dist:', dist, '| find text: ', train_sents_raw_df.iloc[ind, 0], '| label: ', train_sents_raw_df.iloc[ind, 1])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 1.0),\n",
       " (30, 1.0),\n",
       " (62, 1.0),\n",
       " (248, 1.0),\n",
       " (273, 0.3180182373278404),\n",
       " (287, 0.3137614001264736),\n",
       " (152, 0.31080402439309984),\n",
       " (2622, 0.30552693923793095),\n",
       " (116, 0.29971639300159225),\n",
       " (2668, 0.2990710798831687)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(distances.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для строительства предполагается использовать мобильные здания типа «Ермак» (здания «Ермак 600», длина 6,1м, ширина 2,5 м и «Ермак-800», длина 8 м, ширина 2,8 м).\n"
     ]
    }
   ],
   "source": [
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Для всех технологических трубопроводов, за исключением трубопроводов сброса на свечу рассеивания, максимальное рабочее давление принято равным расчетному давлению.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.activation.Softmax"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DocModelForMaskedLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self, DocModelForMaskedLM).__init__()\n",
    "        config = BertConfig.from_pretrained('DeepPavlov/rubert-base-cased-sentence')\n",
    "        self.bert_model = BertModel.from_pretrained('DeepPavlov/rubert-base-cased-sentence', config=config)\n",
    "        self.dense_layer = nn.Linear(config.hidden_size, self.hidden_neurons)\n",
    "        self.out_layer = nn.Linear(self.hidden_neurons, config.vocab_size)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.activation = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, inputs, labels):\n",
    "        seq_output = bert_model(**inputs, labels=labels)\n",
    "        pooled_output = self.dropout(seq_output.mean(axis=0))\n",
    "        output = self.out_layer(self.dense_layer(pooled_output))\n",
    "        output = self.dropout(output)\n",
    "        return self.activation(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv('./data/table_3.csv')\n",
    "table_cols = table.isnull().sum() == table.isnull().sum().max()\n",
    "not_null_cols = table_cols[table_cols == False].index\n",
    "table[not_null_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "\n",
    "table = camelot.read_pdf('pdf_paths[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
